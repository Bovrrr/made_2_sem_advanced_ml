{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from typing import (\n",
    "    List,\n",
    "    Dict,\n",
    "    Optional,\n",
    ")\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 5\n",
    "DATA_PATH = \"raw_data\"\n",
    "AK_FILE = \"AnnaKarenina\"\n",
    "WNP_RU_FILE = \"WarAndPeace\"\n",
    "WNP_EN_FILE = \"WarAndPeaceEng\"\n",
    "TXT = \".txt\"\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnp_ru = None\n",
    "with open(f\"{DATA_PATH}/{WNP_RU_FILE}{TXT}\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wnp_ru = f.read()\n",
    "assert wnp_ru is not None\n",
    "\n",
    "\n",
    "wnp_eng = None\n",
    "with open(f\"{DATA_PATH}/{WNP_EN_FILE}{TXT}\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wnp_eng = f.read()\n",
    "assert wnp_eng is not None\n",
    "\n",
    "\n",
    "ak = None\n",
    "with open(f\"{DATA_PATH}/{AK_FILE}{TXT}\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ak = f.read()\n",
    "assert ak is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "* подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "* возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "* расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreproccesing:\n",
    "    def __init__(self, text: str, ru_en: str = \"ru\") -> None:\n",
    "        try:\n",
    "            self.alph = \"А-Яа-я\" if ru_en == \"ru\" else \"A-Za-z\"\n",
    "            self.alphabet = (\n",
    "                \"абвгдеёжзийклмнопрстуфхцчшщъыьэюя\"\n",
    "                if ru_en == \"ru\"\n",
    "                else \"abcdefghijklmnopqrstuvwxyz\"\n",
    "            )\n",
    "            self.regex = re.compile(f\"[\\W_\\d]+|[^{self.alph}]+\")\n",
    "            self.original_text = self.regex.sub(\" \", text.lower()).strip()\n",
    "        except BaseException as e:\n",
    "            print(f\"error with text processing\")\n",
    "            print(e)\n",
    "\n",
    "    def count_letters_freq(self):\n",
    "        self.counter: Optional[Counter] = Counter(self.original_text)\n",
    "        for letter in self.alphabet:\n",
    "            if letter not in self.counter.keys():\n",
    "                self.counter[letter] = 0\n",
    "        self.letter_freq_seq = [\n",
    "            letter\n",
    "            for letter, freq in sorted(\n",
    "                self.counter.items(),\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True,\n",
    "            )\n",
    "        ]\n",
    "        self.alphabet_len = len(self.alphabet)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def decode(self, text_preprocessed: TextPreproccesing) -> str:\n",
    "        assert self.alph == text_preprocessed.alph\n",
    "        decode_dict = {\n",
    "            self.letter_freq_seq[i]: text_preprocessed.letter_freq_seq[i]\n",
    "            for i in range(self.alphabet_len)\n",
    "        }\n",
    "        return \"\".join(map(lambda x: decode_dict[x], text_preprocessed.original_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "война и мир самый известный роман льва николаевича толстого как никакое другое произведение писателя отражает глубину его мироощущения и философии эта книга из разряда вечных потому что она обо всем о жизни и смерти о любви и чести о мужестве и героизме о славе и подвиге о войне и мире первый том знакомит с высшим обществом россии  века показаны взаимоотношения между родителями и детьми в семье ро\n",
      "[' ', 'о', 'а', 'е', 'и', 'н', 'т', 'с', 'л', 'в', 'р', 'к', 'д', 'м', 'у', 'п', 'я', 'г', 'ь', 'ы', 'з', 'б', 'ч', 'й', 'ж', 'ш', 'х', 'ю', 'ц', 'э', 'щ', 'ф', 'ъ', 'ё']\n",
      "CPU times: user 129 ms, sys: 8.01 ms, total: 137 ms\n",
      "Wall time: 137 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "wnp_ru_processed = TextPreproccesing(wnp_ru).count_letters_freq()\n",
    "print(wnp_ru_processed.alphabet_len)\n",
    "print(wnp_ru_processed.original_text[:100*4])\n",
    "print(wnp_ru_processed.letter_freq_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncode:\n",
    "    \"\"\"class for ceaser encoding\"\"\"\n",
    "\n",
    "    def __init__(self, shift: int = 1, ru_en: str = \"ru\") -> None:\n",
    "        self.alph = \"А-Яа-я\" if ru_en == \"ru\" else \"A-Za-z\"\n",
    "        self.alphabet = (\n",
    "            \"абвгдеёжзийклмнопрстуфхцчшщъыьэюя\"\n",
    "            if ru_en == \"ru\"\n",
    "            else \"abcdefghijklmnopqrstuvwxyz\"\n",
    "        )\n",
    "        self.shift = shift % len(self.alphabet)\n",
    "\n",
    "        self.encode_dict = {\n",
    "            origin_letter: self.alphabet[(i + self.shift) % 33]\n",
    "            for i, origin_letter in enumerate(self.alphabet)\n",
    "        }\n",
    "        self.encode_dict[\" \"] = \" \"\n",
    "        self.decode_dict = {v: k for k, v in self.encode_dict.items()}\n",
    "\n",
    "    def encode(self, text: str) -> str:\n",
    "        return \"\".join(map(lambda x: self.encode_dict[x], text))\n",
    "\n",
    "    def decode(self, text: str) -> str:\n",
    "        return \"\".join(map(lambda x: self.decode_dict[x], text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "статья википедии с препроцессингом\n",
      "андрей николаевич колмогоров апреля тамбов октября\n",
      "--------------------------------------------------\n",
      "зашифрованная статья википедии с препроцессингом\n",
      "боесёк ойлпмбёгйш лпмнпдпспг брсёма убнвпг плуавса\n"
     ]
    }
   ],
   "source": [
    "class TestTexts:\n",
    "    Kolmogorov_wiki = \"\"\"Андрей Николаевич Колмогоров (12 (25) апреля 1903, Тамбов — 20 октября 1987, Москва) — советский математик, один из крупнейших математиков XX века. Один из основоположников современной теории вероятностей, им получены фундаментальные результаты в топологии, геометрии, математической логике, классической механике, теории турбулентности, теории сложности алгоритмов, теории информации, теории функций, теории тригонометрических рядов, теории меры, теории приближения функций, теории множеств, теории дифференциальных уравнений, теории динамических систем, функциональном анализе и в ряде других областей математики и её приложений. Автор новаторских работ по философии, истории, методологии и преподаванию математики, известны его работы в статистической физике (в частности, уравнение Джонсона — Мела — Аврами — Колмогорова).\n",
    "\n",
    "    Профессор Московского государственного университета (с 1931), доктор физико-математических наук, академик Академии наук СССР (1939). Президент Московского математического общества (ММО) в 1964—1966 и 1974—1985 годах. Герой Социалистического Труда (1963). Лауреат Ленинской и Сталинской премии.\n",
    "\n",
    "    Иностранный член Национальной академии наук США (1967)[8], Лондонского королевского общества (1964)[9], Французской (Парижской) академии наук (1966)[10], член Германской академии естествоиспытателей «Леопольдина» (1959), почётный член Американской академии искусств и наук (1959), иностранный член Венгерской академии наук (1965), Польской академии наук (1956), Нидерландской королевской академии наук (1963), АН ГДР (1977), Академии наук Финляндии (1985), почётный член Румынской академии. Член Лондонского математического общества (1962), Индийского математического общества (1962), иностранный член Американского философского общества (1961). Почётный доктор Парижского университета (1955), Стокгольмского университета (1960), Индийского статистического института  (англ.)рус. в Калькутте (1962).\"\"\"\n",
    "\n",
    "\n",
    "Kolmogorov_wiki_processed = TextPreproccesing(TestTexts.Kolmogorov_wiki)\n",
    "Kolmogorov_wiki_encoded = TextEncode().encode(Kolmogorov_wiki_processed.original_text)\n",
    "Kolmogorov_wiki_enc_processed = TextPreproccesing(\n",
    "    Kolmogorov_wiki_encoded\n",
    ").count_letters_freq()\n",
    "print(\n",
    "    f\"статья википедии с препроцессингом\\n{Kolmogorov_wiki_processed.original_text[:50]}\"\n",
    ")\n",
    "print(\"--\" * 25)\n",
    "print(\n",
    "    f\"зашифрованная статья википедии с препроцессингом\\n{Kolmogorov_wiki_encoded[:50]}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(original: str, decoded: str) -> float:\n",
    "    return sum(\n",
    "        [\n",
    "            1\n",
    "            for i in range(min(len(original), len(decoded)))\n",
    "            if original[i] == decoded[i]\n",
    "        ]\n",
    "    ) / min(len(original), len(decoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0514839491217444"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(\n",
    "    Kolmogorov_wiki_processed.original_text, Kolmogorov_wiki_enc_processed.original_text\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ипбл г пэсфки рэз сфкуфефлфр имл кй диунфр фсдйнлй уфтсри тфр дтсэг уид уидэс фбэп эо слжмп гёэщ уид уидэсфр р си фбэп эо фтпфрфмфкфвпэсфр тфрл у ппфг д флээ р лфйдпфтд г эу мфкжз пх чжпбиу пдикяпх л ожкядидх р дфмфкфеээ е фу длээ уид уидэз тсфг кфеэс скиттэз тсфг у щипэс д флээ джлнжк пдпфтдэ д флээ ткфвпфтдэ икефлэдуфр д флээ эпчфлуицээ д флээ чжпсцэг д флээ длэефпфу длэз тсэщ лйбфр д флээ у лх д флээ млэнкэв пэй чжпсцэг д флээ упфв тдр д флээ бэчч л пцэикяпхщ жлирп пэг д флээ бэпиуэз тсэщ тэтд у чжпсцэфпикяпфу ипикэо э р лйб блжеэщ фнкитд г уид уидэсэ э  млэкфв пэг ирдфл пфридфлтсэщ линфд мф чэкфтфчээ этдфлээ у дфбфкфеээ э мл мфбирипэш уид уидэсэ эор тдпх  еф линфдх р тдидэтдэз тсфг чэоэс р зитдпфтдэ жлирп пэ бвфптфпи у ки ирлиуэ сфкуфефлфри млфч ттфл уфтсфртсфеф ефтжбилтдр ппфеф жпэр лтэд ди т бфсдфл чэоэсф уид уидэз тсэщ пижс исиб уэс исиб уээ пижс тттл мл оэб пд уфтсфртсфеф уид уидэз тсфеф фны тдри ууф р э ефбищ е лфг тфцэикэтдэз тсфеф длжби кижл ид к пэптсфг э тдикэптсфг мл уээ эпфтдлиппхг зк п пицэфпикяпфг исиб уээ пижс тёи кфпбфптсфеф сфлфк ртсфеф фны тдри члипцжотсфг милэвтсфг исиб уээ пижс зк п е луиптсфг исиб уээ  тд тдрфэтмхдид к г к фмфкябэпи мфз дпхг зк п иу лэсиптсфг исиб уээ этсжттдр э пижс эпфтдлиппхг зк п р пе лтсфг исиб уээ пижс мфкятсфг исиб уээ пижс пэб лкипбтсфг сфлфк ртсфг исиб уээ пижс ип ебл исиб уээ пижс чэпкйпбээ мфз дпхг зк п лжухптсфг исиб уээ зк п кфпбфптсфеф уид уидэз тсфеф фны тдри эпбэгтсфеф уид уидэз тсфеф фны тдри эпфтдлиппхг зк п иу лэсиптсфеф чэкфтфчтсфеф фны тдри мфз дпхг бфсдфл милэвтсфеф жпэр лтэд ди тдфсефкяутсфеф жпэр лтэд ди эпбэгтсфеф тдидэтдэз тсфеф эптдэджди ипек лжт р сикясждд'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnp_ru_processed.decode(Kolmogorov_wiki_enc_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего не понятно. Расшифровка по частоте n-грамм с n=1 работает не очень даже на таких текстах размером с небольшую статью википедии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    " * подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    " * проведите тестирование аналогично п.1, но при помощи биграмм.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая большая и очевидная проблема, с которой я столкнулся - это то, как делать расшифровку, потому что биграммам с высокой частотностью мы доверяем больше и нужно как-то сначала их использовать, а потом на том, что останется остальные.\n",
    "\n",
    "Или нужно как-то изначально кодировать по другому тоже сразу биграммами. Я не придумал как бороться с этой проблемой единственно верным путём, поэтому решил с ней вообще не бороться.\n",
    "\n",
    "\n",
    "(+- хорошие способы, которые мне пришли в голову - это \n",
    "1. построить график скалистой осыпи для частот биграмм, отсечь по острому углу. Использовать только эти биграммы для декодирования, а остальное декодировать как в пункте 1. Но я не знаю как реализовать общее решение для всех текстов даже на 1-ом языке.\n",
    "2. сначала менять только перавые биграммы слов, а потом дальше уже идти и выбирать только те биграммы, которые начинаются на конец первых и тд.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "alphabet_ru = \"абвгдеёжзийклмнопрстуфхцчшщъыьэюя\"\n",
    "alphabet_en = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "\n",
    "class BigrammFreq:\n",
    "    def __init__(self, text: str, bigramm_freq_dict: Dict[str, int]):\n",
    "        self.text: str = \" \".join([word for word in text.split() if len(word) > 1])\n",
    "        self.bigramm_freq_dict: Dict[str, int] = bigramm_freq_dict\n",
    "\n",
    "    def update_bigramm_freq(self, word: str) -> None:\n",
    "        for i in range(len(word) - 1):\n",
    "            self.bigramm_freq_dict[word[i : i + 2]] += 1\n",
    "\n",
    "    def count_bigramm_freq(self):\n",
    "        for word in self.text.split():\n",
    "            self.update_bigramm_freq(word)\n",
    "\n",
    "        self.freq_ordered_bigramms: List[str] = [\n",
    "            k\n",
    "            for k, v in sorted(\n",
    "                self.bigramm_freq_dict.items(),\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True,\n",
    "            )\n",
    "        ]\n",
    "        return self\n",
    "\n",
    "    def decode(self, another: BigrammFreq):\n",
    "        decode_dict = {\n",
    "            another.freq_ordered_bigramms[i]: self.freq_ordered_bigramms[i]\n",
    "            for i in range(33 * 33)\n",
    "        }\n",
    "\n",
    "        def decode_word(word: str) -> str:\n",
    "            return \"\".join(\n",
    "                [decode_dict[word[i : i + 2]] for i in range(len(word) - 2)]\n",
    "            )[::2]\n",
    "\n",
    "        return \" \".join(\n",
    "            map(\n",
    "                decode_word,\n",
    "                [word for word in another.text.split()],\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_bigramm_freq_dict_wnp_ru = {\n",
    "    \"\".join(k): 0 for k in list(product(alphabet_ru, repeat=2))\n",
    "}\n",
    "ru_bigramm_freq_dict_Kolmogorov = {\n",
    "    \"\".join(k): 0 for k in list(product(alphabet_ru, repeat=2))\n",
    "}\n",
    "\n",
    "wnp_ru_bigramm_freq = BigrammFreq(\n",
    "    wnp_ru_processed.original_text,\n",
    "    ru_bigramm_freq_dict_wnp_ru,\n",
    ").count_bigramm_freq()\n",
    "kolmogorov_bigramm_freq = BigrammFreq(\n",
    "    Kolmogorov_wiki_enc_processed.original_text,\n",
    "    ru_bigramm_freq_dict_Kolmogorov,\n",
    ").count_bigramm_freq()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06346153846153846"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(\n",
    "    Kolmogorov_wiki_processed.original_text,\n",
    "    wnp_ru_bigramm_freq.decode(kolmogorov_bigramm_freq),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало лучше на 1 сотую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'оо оотл ы тлканапа к  рдла исьиы ансу ж усд к кно нт  лос оы к кноот  нт  нрелаерлвтооот жл ре пр анялен  рлщ  мбов иратд шгтарн аерлвнн  ор к кно ст внн уаавс ст воо пр иаеу иленн пр ывтоенн аааприна пр ебапикше пр мбепе пр орваое ор сд ымм пр  пр ерлэи о мбепе пр ие н пр те себатдт асс о пр тевдо сд св мбепеуоватде оваи ы соен чэаа к кноо еркв о сеа елинаптсд сба  еквнжке внапр анмлвнн  рнвсиоо к кноо л нл  сбаи нрновно ст елв данленн асс  иуозжо  стсд тлканапал еа вж анстлчстн анждвмтн рен бо тс  миса елво к кно сд вп ер о ер о вп вв  в  анстлчстн к кно стн ч на б анв а жжебаивно стн оод ап  оезст нраиезст  о еенносорт  вшеуоватде ер о вп г воомозстн тпа чстн ч на асосьуяст омридст ер о вп  икозст ер о  наамвезяр ерлтоте р лт   ророзст ер о всидвн вп еенносорт   тст ер о вп рлтуст ер о вп о цаоосст тпа чст ер о вп  р ер о вп ееблтот р лт  оаптзст ер о  воомозстн к кно стн ч на еотдтстн к кно стн ч на еенносорт   ророзстн еквнжкестн ч на р лт миса омридстн бо тс  наивалтячстн бо тс  еотдтстн нрновно стн езноиио ос о ратгио'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnp_ru_bigramm_freq.decode(kolmogorov_bigramm_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    " * предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    " * реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Про MCMC читал и ориентировался на статью с Хабра\n",
    "\n",
    "https://habr.com/ru/company/wunderfund/blog/279545/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from nltk import everygrams\n",
    "\n",
    "\n",
    "def get_ngram_freqs(text, n_gram=2):\n",
    "    vocab_size = len(set(text)) ** n_gram\n",
    "    if n_gram > 1:\n",
    "        text = [\n",
    "            \"\".join(ngram) for ngram in everygrams(text, min_len=n_gram, max_len=n_gram)\n",
    "        ]\n",
    "    freqs = {k: (v + 1) / (len(text) + vocab_size) for k, v in Counter(text).items()}\n",
    "    return freqs\n",
    "\n",
    "\n",
    "def get_text_proba(\n",
    "    text: str,\n",
    "    mapping: Dict,\n",
    "    freqs: Dict,\n",
    "    n_gram: int = 2,\n",
    "    alphabet: str = alphabet_ru,\n",
    "):\n",
    "    decoded_text = \"\".join([mapping.get(c, \" \") for c in text])\n",
    "    log_proba = 0.0\n",
    "    for i in range(len(decoded_text) - n_gram):\n",
    "        ngram = decoded_text[i : i + n_gram]\n",
    "        ngram_proba = freqs.get(ngram, 1 / (len(text) + len(alphabet) ** n_gram))\n",
    "        log_proba += np.log(ngram_proba)\n",
    "    return log_proba\n",
    "\n",
    "\n",
    "def get_reverse_mapping_mcmc(\n",
    "    enc_text,\n",
    "    alphabet,\n",
    "    freqs,\n",
    "    n_iters=int(1e4),\n",
    "    n_trials=12,\n",
    "    n_gram=2,\n",
    "):\n",
    "    accept_num = 0\n",
    "    best_reverse_mapping = None\n",
    "    mapping_collection = []\n",
    "    best_log_likelihood = -np.inf\n",
    "    alphabet = list(alphabet)\n",
    "\n",
    "    for trial in tqdm(range(n_trials), leave=False, position=0, total=n_trials):\n",
    "        alphabet_iter = list(alphabet)\n",
    "        reverse_mapping = {\n",
    "            k: v for k, v in zip(alphabet, alphabet_iter[: len(alphabet)])\n",
    "        }\n",
    "        log_proba_current = get_text_proba(\n",
    "            enc_text, reverse_mapping, freqs, n_gram=n_gram\n",
    "        )\n",
    "\n",
    "        for i in range(n_iters):\n",
    "            alphabet_proposal = alphabet_iter[:]\n",
    "            idx1, idx2 = np.random.choice(len(alphabet_proposal), replace=False, size=2)\n",
    "            alphabet_proposal[idx1], alphabet_proposal[idx2] = (\n",
    "                alphabet_proposal[idx2],\n",
    "                alphabet_proposal[idx1],\n",
    "            )\n",
    "            reverse_mapping_proposal = {\n",
    "                k: v for k, v in zip(alphabet, alphabet_proposal[: len(alphabet)])\n",
    "            }\n",
    "            log_proba_proposal = get_text_proba(\n",
    "                enc_text, reverse_mapping_proposal, freqs, n_gram=n_gram\n",
    "            )\n",
    "\n",
    "            p_accept = np.exp(log_proba_proposal - log_proba_current)\n",
    "\n",
    "            if p_accept > np.random.rand():\n",
    "                accept_num += 1\n",
    "                alphabet_iter = alphabet_proposal\n",
    "                log_proba_current = log_proba_proposal\n",
    "                reverse_mapping = reverse_mapping_proposal\n",
    "\n",
    "        if log_proba_current > best_log_likelihood:\n",
    "            best_log_likelihood = log_proba_current\n",
    "            best_reverse_mapping = reverse_mapping\n",
    "\n",
    "        mapping_collection.append(reverse_mapping)\n",
    "\n",
    "    print(\"Likelihood: {best_log_likelihood}\")\n",
    "    print(f\"Accept \\%: {accept_num / (n_iters * n_trials)}\")\n",
    "    return best_reverse_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5c1770553b454ba0a8251b92caffc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: {best_log_likelihood}\n",
      "Accept \\%: 0.022458333333333334\n"
     ]
    }
   ],
   "source": [
    "freqs = get_ngram_freqs(\n",
    "    wnp_ru_processed.original_text,\n",
    ")\n",
    "rev_map = get_reverse_mapping_mcmc(\n",
    "    enc_text=Kolmogorov_wiki_enc_processed.original_text,\n",
    "    alphabet=alphabet_ru + \" \",\n",
    "    freqs=freqs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_kolmogorov_text = \"\".join(\n",
    "    [rev_map.get(c, \" \") for c in Kolmogorov_wiki_enc_processed.original_text]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.1901877649909146\n",
      "андр й нитола мия толвогором апр лу кавёом откуёру востма сом кстий вак вакит один ич трепн йжих вак вакитом м та один ич осномополознитом сомр в нной к ории м роукноск й ив полея ны бендав нкальны р челькакы м копологии г ов крии вак вакия стой логит тлассия стой в ханит к ории керёел нкноски к ории слозноски алгориквом к ории инборвашии к ории бентший к ории кригонов крия стих рудом к ории в ры к ории приёлиз ниу бентший к ории вноз скм к ории дибб р ншиальных ерамн ний к ории динавия стих сиск в бентшиональнов аналич и м руд дрегих оёласк й вак вакити и  прилоз ний амкор номакорстих раёок по билособии искории в кодологии и пр подаманиц вак вакити ичм скны  го раёокы м скакиския стой бичит м яаскноски ерамн ни дзонсона в ла амрави толвогорома проб ссор востомстого госедарскм нного еним рсик ка с доткор бичито вак вакия стих нает атад вит атад вии нает ссср пр чид нк востомстого вак вакия стого оёю скма вво м и годах г рой сошиалиския стого креда лаер ак л нинстой и скалинстой пр вии иноскранный ял н нашиональной атад вии нает сжа лондонстого торол мстого оёю скма браншечстой паризстой атад вии нает ял н г рванстой атад вии  ск скмоиспыкак л й л опольдина поя кный ял н ав ританстой атад вии истесскм и нает иноскранный ял н м нг рстой атад вии нает польстой атад вии нает нид рландстой торол мстой атад вии нает ан гдр атад вии нает бинлундии поя кный ял н ревынстой атад вии ял н лондонстого вак вакия стого оёю скма индийстого вак вакия стого оёю скма иноскранный ял н ав ританстого билособстого оёю скма поя кный доткор паризстого еним рсик ка скотгольвстого еним рсик ка индийстого скакиския стого инскикека англ рес м тальтекк\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Accuracy:\\n{accuracy(Kolmogorov_wiki_enc_processed.original_text, decoded_kolmogorov_text,)}\",\n",
    "    decoded_kolmogorov_text,\n",
    "    sep=\"\\n\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результат очень сильно улучшился.\n",
    "# Точность правильно определённых букв выросла кратно(х3) по сравнению с простым сопостовлением биграмм, отранжированных по их частотам."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
